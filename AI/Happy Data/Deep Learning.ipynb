{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381750 entries, 0 to 381749\n",
      "Columns: 129 entries, CH1 to Label\n",
      "dtypes: float64(129)\n",
      "memory usage: 375.7 MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('TYPASD.csv')\n",
    "# df.head(22)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TIME_STEPS = 250\n",
    "N_FEATURES = 128 #128\n",
    "step = 10 # 20\n",
    "segments = []\n",
    "for i in range(0, len(df) - N_TIME_STEPS, step):\n",
    "    ch = []\n",
    "    for j in range(0, N_FEATURES):\n",
    "        ch.append(df.iloc[:, j].values[i: i + N_TIME_STEPS])\n",
    "    segments.append(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(0, len(df) - N_TIME_STEPS, step):\n",
    "    label = stats.mode(df['Label'][i: i + N_TIME_STEPS])[0][0]\n",
    "    labels.append(label)\n",
    "labelsl = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "#print(labelsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        reshaped_segments, labelsl, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38150, 128, 250) (38150, 250, 128) [1. 0.] 30520 7630\n"
     ]
    }
   ],
   "source": [
    "print(np.array(segments).shape, reshaped_segments.shape, labelsl[0], len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 2\n",
    "N_HIDDEN_UNITS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@curiousily/human-activity-recognition-using-lstms-on-android-tensorflow-for-hackers-part-vi-492da5adef64\n",
    "def create_LSTM_model(inputs):\n",
    "    W = {\n",
    "        'hidden': tf.Variable(tf.random_normal([N_FEATURES, N_HIDDEN_UNITS])),\n",
    "        'output': tf.Variable(tf.random_normal([N_HIDDEN_UNITS, N_CLASSES]))\n",
    "    }\n",
    "    biases = {\n",
    "        'hidden': tf.Variable(tf.random_normal([N_HIDDEN_UNITS], mean=1.0)),\n",
    "        'output': tf.Variable(tf.random_normal([N_CLASSES]))\n",
    "    }\n",
    "    \n",
    "    X = tf.transpose(inputs, [1, 0, 2])\n",
    "    X = tf.reshape(X, [-1, N_FEATURES])\n",
    "    hidden = tf.nn.relu(tf.matmul(X, W['hidden']) + biases['hidden'])\n",
    "    hidden = tf.split(hidden, N_TIME_STEPS, 0)\n",
    "\n",
    "    # Stack 2 LSTM layers\n",
    "    lstm_layers = [tf.contrib.rnn.BasicLSTMCell(N_HIDDEN_UNITS, forget_bias=1.0) for _ in range(2)]\n",
    "    lstm_layers = tf.contrib.rnn.MultiRNNCell(lstm_layers)\n",
    "\n",
    "    outputs, _ = tf.contrib.rnn.static_rnn(lstm_layers, hidden, dtype=tf.float32)\n",
    "\n",
    "    # Get output for the last time step\n",
    "    lstm_last_output = outputs[-1]\n",
    "\n",
    "    return tf.matmul(lstm_last_output, W['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, N_TIME_STEPS, N_FEATURES], name=\"input\")\n",
    "Y = tf.placeholder(tf.float32, [None, N_CLASSES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-8-c8ae7df74e6e>:17: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-c8ae7df74e6e>:18: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-c8ae7df74e6e>:20: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "pred_Y = create_LSTM_model(X)\n",
    "\n",
    "pred_softmax = tf.nn.softmax(pred_Y, name=\"y_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_LOSS = 0.0015\n",
    "\n",
    "l2 = L2_LOSS * \\\n",
    "    sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred_Y, labels = Y)) + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0025\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred_softmax, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50  # 50\n",
    "BATCH_SIZE = 1024  # 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 test accuracy: 0.5247706174850464 loss: 6.698835849761963\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@curiousily/human-activity-recognition-using-lstms-on-android-tensorflow-for-hackers-part-vi-492da5adef64\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "history = dict(train_loss=[], \n",
    "                     train_acc=[], \n",
    "                     test_loss=[], \n",
    "                     test_acc=[])\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_count = len(X_train)\n",
    "\n",
    "for i in range(1, N_EPOCHS + 1):\n",
    "    for start, end in zip(range(0, train_count, BATCH_SIZE),\n",
    "                          range(BATCH_SIZE, train_count + 1,BATCH_SIZE)):\n",
    "        sess.run(optimizer, feed_dict={X: X_train[start:end],\n",
    "                                       Y: y_train[start:end]})\n",
    "\n",
    "    _, acc_train, loss_train = sess.run([pred_softmax, accuracy, loss], feed_dict={\n",
    "                                            X: X_train, Y: y_train})\n",
    "\n",
    "    _, acc_test, loss_test = sess.run([pred_softmax, accuracy, loss], feed_dict={\n",
    "                                            X: X_test, Y: y_test})\n",
    "\n",
    "    history['train_loss'].append(loss_train)\n",
    "    history['train_acc'].append(acc_train)\n",
    "    history['test_loss'].append(loss_test)\n",
    "    history['test_acc'].append(acc_test)\n",
    "\n",
    "#     if i != 1 and i % 10 != 0:\n",
    "#         continue\n",
    "\n",
    "    print(f'epoch: {i} test accuracy: {acc_test} loss: {loss_test}')\n",
    "    \n",
    "predictions, acc_final, loss_final = sess.run([pred_softmax, accuracy, loss], feed_dict={X: X_test, Y: y_test})\n",
    "\n",
    "print()\n",
    "print(f'final results: accuracy: {acc_final} loss: {loss_final}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@curiousily/human-activity-recognition-using-lstms-on-android-tensorflow-for-hackers-part-vi-492da5adef64\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(np.array(history['train_loss']), \"r--\", label=\"Train loss\")\n",
    "plt.plot(np.array(history['train_acc']), \"g--\", label=\"Train accuracy\")\n",
    "\n",
    "plt.plot(np.array(history['test_loss']), \"r-\", label=\"Test loss\")\n",
    "plt.plot(np.array(history['test_acc']), \"g-\", label=\"Test accuracy\")\n",
    "\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.ylabel('Training Progress (Loss or Accuracy values)')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_info = [N_HIDDEN_UNITS, BATCH_SIZE, N_EPOCHS]\n",
    "\n",
    "dirname = os.path.dirname(\"nhid-{}_bat-{}_nepoc-{}/dumps/\".format(*file_info))\n",
    "if not os.path.exists(dirname):\n",
    "    os.makedirs(dirname)\n",
    "dirname = os.path.dirname(\"nhid-{}_bat-{}_nepoc-{}/logs/\".format(*file_info))\n",
    "if not os.path.exists(dirname):\n",
    "    os.makedirs(dirname)\n",
    "\n",
    "pickle.dump(predictions, open(\"nhid-{}_bat-{}_nepoc-{}/dumps/predictions.p\".format(*file_info), \"wb\"))\n",
    "pickle.dump(history, open(\"nhid-{}_bat-{}_nepoc-{}/dumps/history.p\".format(*file_info), \"wb\"))\n",
    "tf.train.write_graph(sess.graph, \"nhid-{}_bat-{}_nepoc-{}/logs\".format(*file_info), 'har.pbtxt')  \n",
    "saver.save(sess, 'nhid-{}_bat-{}_nepoc-{}/logs/har.ckpt'.format(*file_info))\n",
    "\n",
    "writer = tf.summary.FileWriter('nhid-{}_bat-{}_nepoc-{}/logs'.format(*file_info))\n",
    "writer.add_graph(sess.graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
